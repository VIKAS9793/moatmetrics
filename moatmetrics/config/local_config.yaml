ai:
  ollama_base_url: "http://localhost:11434"
  default_model: "tinyllama"
  timeout: 300  # 5 minutes
  max_retries: 3
  temperature: 0.7
  max_tokens: 2000
